{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Making Translation Machine using Encoder-Decoder Transformer**"
      ],
      "metadata": {
        "id": "lA3_DRglS-ao"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqI_fmr08Ap6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F  # ganti import functional\n",
        "import math\n",
        "import random\n",
        "from collections import Counter\n",
        "import json\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.optim as optim\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building a Attention and Cross Attention**"
      ],
      "metadata": {
        "id": "T-PM5y35TFzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Motivation** :  Traditional RNN have a problem with long-range dependecies and also vanishing gradient. Therefore, we using a self-attention to capture relationship of distance by comparing all tokens to all tokens."
      ],
      "metadata": {
        "id": "pI7fBo3HnB7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key concepts of Self-attention:\n",
        "1. We have to aware that the input of model is a sequence which is a vector embedding.\n",
        "2. In Self-attention, we want to compute queries, keys and values (Query, Key, Value) -> Query = Weight * Xi.\n",
        "3. After that, we have to computer a attention scores = (Query @ Key) / sqrt(dk) where dk is the dimension of key vector.\n",
        "4. Apply nomralize score : softmax -> Softmax(score of attention).\n",
        "5. Weighted sum of values -> sum(normalize score)."
      ],
      "metadata": {
        "id": "xUsvew4_nkic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, heads):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.heads = heads\n",
        "        self.head_dim = embed_dim // heads\n",
        "        assert self.head_dim * heads == embed_dim, \"embed_dim must be divisible by heads\"\n",
        "\n",
        "        self.query = nn.Linear(embed_dim, embed_dim)\n",
        "        self.key = nn.Linear(embed_dim, embed_dim)\n",
        "        self.value = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "        self.unify_heads = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "      batch_size = query.shape[0]\n",
        "      seq_len_q = query.shape[1]\n",
        "      seq_len_k = key.shape[1]\n",
        "\n",
        "      Q = self.query(query).view(batch_size, seq_len_q, self.heads, self.head_dim).transpose(1, 2)\n",
        "      K = self.key(key).view(batch_size, seq_len_k, self.heads, self.head_dim).transpose(1, 2)\n",
        "      V = self.value(value).view(batch_size, seq_len_k, self.heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "      scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "      if mask is not None:\n",
        "          mask = mask.to(scores.device)\n",
        "          scores = scores.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "      attn = torch.softmax(scores, dim=-1)\n",
        "\n",
        "      out = torch.matmul(attn, V)\n",
        "      out = out.transpose(1, 2).contiguous().view(batch_size, seq_len_q, self.embed_dim)\n",
        "\n",
        "      return self.unify_heads(out)\n"
      ],
      "metadata": {
        "id": "M5i3H6P7D_ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multi-Head Attention**"
      ],
      "metadata": {
        "id": "Vxl17aeJPMMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Self_Attention(nn.Module):\n",
        "  def __init__(self,embedding_dim, heads):\n",
        "    super().__init__()\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.heads = heads\n",
        "    self.heads_dim = embedding_dim // heads\n",
        "    assert self.heads_dim * heads == embedding_dim, \"embed_dim must be divisible by heads\"\n",
        "\n",
        "    # Linear layer q,k,v\n",
        "    self.query = nn.Linear(embedding_dim,embedding_dim)\n",
        "    self.key = nn.Linear(embedding_dim,embedding_dim)\n",
        "    self.value = nn.Linear(embedding_dim,embedding_dim)\n",
        "\n",
        "    self.output = nn.Linear(embedding_dim,embedding_dim)\n",
        "  def forward(self, x, mask=None):\n",
        "        batch_size, seq_len, embed_dim = x.shape\n",
        "\n",
        "        Q = self.query(x)\n",
        "        K = self.key(x)\n",
        "        V = self.value(x)\n",
        "\n",
        "        Q = Q.view(batch_size, seq_len, self.heads, self.heads_dim).transpose(1, 2)\n",
        "        K = K.view(batch_size, seq_len, self.heads, self.heads_dim).transpose(1, 2)\n",
        "        V = V.view(batch_size, seq_len, self.heads, self.heads_dim).transpose(1, 2)\n",
        "\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.heads_dim)\n",
        "\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        out = torch.matmul(attn, V)\n",
        "        out = out.transpose(1, 2).contiguous().view(batch_size, seq_len, embed_dim)\n",
        "        return self.output(out)"
      ],
      "metadata": {
        "id": "gLehPMVxqAPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test case\n",
        "input = torch.zeros(10,4,256) # 10 sentence, length paragraphnya = 4 kata dan vector emb 256\n",
        "Model_testing = Self_Attention(embedding_dim=256,heads=8)\n",
        "output = Model_testing(input)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGO2Hc5kuPAM",
        "outputId": "f2b77406-4784-47cf-be77-ff3f161e50f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building Feed-Forward**"
      ],
      "metadata": {
        "id": "8SVXekt0TbG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feed Forward** : Use for learning non-linear"
      ],
      "metadata": {
        "id": "k4ufGwFwvA6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self,embed_dim,ff_dim):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(embed_dim,ff_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(ff_dim,embed_dim)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "RHFTudSX3ZlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.zeros(256,256)\n",
        "model_testing = FeedForward(256,1024)\n",
        "print(model_testing(input).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ReFeL5o34wI",
        "outputId": "1772150d-4be4-44fb-cdcd-da6b9992e870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building Positional Encoding**"
      ],
      "metadata": {
        "id": "66W-dMjJTgfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positional Encoding :Transformers do not use recurrence or convolution, so they have no inherent sense of token order in sequences. To make the model aware of the order (position) of each token in a sequence, positional encodings are added to the input embeddings.\n",
        "\n"
      ],
      "metadata": {
        "id": "4Fiir5aP6C1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, embed_dim, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, embed_dim)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, embed_dim, 2) * (-math.log(10000.0) / embed_dim))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)  # shape [1, max_len, d_model]\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.size(1)\n",
        "        # slice positional encoding agar sesuai sequence length input x\n",
        "        x = x + self.pe[:, :seq_len, :]\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "uJT2DVJ76hLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 16\n",
        "max_len = 100\n",
        "\n",
        "pos_enc = PositionalEncoding(embed_dim=embed_dim, max_len=max_len)\n",
        "\n",
        "# Buat dummy input: batch_size=2, seq_len=50, embed_dim=16\n",
        "x = torch.zeros(2, 50, embed_dim)\n",
        "\n",
        "# Tambahkan positional encoding\n",
        "out = pos_enc(x)\n",
        "\n",
        "print(\"Input shape:\", x.shape)          # (2, 50, 16)\n",
        "print(\"Output shape:\", out.shape)       # (2, 50, 16)\n",
        "print(\"Output sample:\", out[0, 0, :])   # Positional encoding for first token in batch 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfK311TY8YU7",
        "outputId": "2b2bee33-0242-4575-f276-e4b471c8aa1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 50, 16])\n",
            "Output shape: torch.Size([2, 50, 16])\n",
            "Output sample: tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building Encoder Transformer Block**"
      ],
      "metadata": {
        "id": "GK17xSllTluy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building Encoder Transformer Block** : Input -> Position Encoding -> MultiheadAttn -> Add & Normalization -> Feed Forward -> Add & Normalization"
      ],
      "metadata": {
        "id": "BBYuIcni9niw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, embed_dim, heads, ff_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attention = Self_Attention(embedding_dim=embed_dim, heads=heads)\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.ff = FeedForward(embed_dim=embed_dim, ff_dim=ff_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        attn_out = self.attention(x, mask=mask)\n",
        "        x = self.norm1(x + self.dropout(attn_out))\n",
        "        ff_out = self.ff(x)\n",
        "        x = self.norm2(x + self.dropout(ff_out))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "JrgEyK1M-DMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building Decoder Transformer**"
      ],
      "metadata": {
        "id": "Jm6778a4BVoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, embed_dim, heads, ff_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attention_masked = Self_Attention(embed_dim, heads)\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.cross_attention = CrossAttention(embed_dim, heads)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.ff = FeedForward(embed_dim=embed_dim, ff_dim=ff_dim)\n",
        "        self.norm3 = nn.LayerNorm(embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, x_encoder, tgt_mask=None, src_mask=None):\n",
        "        attn_out = self.attention_masked(x, mask=tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_out))\n",
        "\n",
        "        cross_attn_out = self.cross_attention(query=x, key=x_encoder, value=x_encoder, mask=src_mask)\n",
        "        x = self.norm2(x + self.dropout(cross_attn_out))\n",
        "\n",
        "        ff_out = self.ff(x)\n",
        "        x = self.norm3(x + self.dropout(ff_out))\n",
        "        return x"
      ],
      "metadata": {
        "id": "AJH-rwyUBZcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building Tranformer**"
      ],
      "metadata": {
        "id": "H4yY0Z-EOgWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embed_dim,\n",
        "                 num_heads,\n",
        "                 ff_dim,\n",
        "                 num_encoder_layers,\n",
        "                 num_decoder_layers,\n",
        "                 input_vocab_size,\n",
        "                 target_vocab_size,\n",
        "                 max_seq_len,\n",
        "                 dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed_dim = embed_dim\n",
        "        self.input_embedding = nn.Embedding(input_vocab_size, embed_dim)\n",
        "        self.target_embedding = nn.Embedding(target_vocab_size, embed_dim)\n",
        "        self.positional_encoding = PositionalEncoding(embed_dim, max_seq_len)\n",
        "\n",
        "        self.encoder_layers = nn.ModuleList(\n",
        "            [EncoderLayer(embed_dim, num_heads, ff_dim, dropout) for _ in range(num_encoder_layers)]\n",
        "        )\n",
        "        self.decoder_layers = nn.ModuleList(\n",
        "            [DecoderLayer(embed_dim, num_heads, ff_dim) for _ in range(num_decoder_layers)]\n",
        "        )\n",
        "\n",
        "        self.output_linear = nn.Linear(embed_dim, target_vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
        "      enc_x = self.input_embedding(src) * math.sqrt(self.embed_dim)\n",
        "      enc_x = self.positional_encoding(enc_x)\n",
        "\n",
        "      dec_x = self.target_embedding(tgt) * math.sqrt(self.embed_dim)\n",
        "      dec_x = self.positional_encoding(dec_x)\n",
        "\n",
        "      for layer in self.encoder_layers:\n",
        "          enc_x = layer(enc_x, mask=None)\n",
        "\n",
        "      for layer in self.decoder_layers:\n",
        "          dec_x = layer(dec_x, enc_x, tgt_mask=tgt_mask, src_mask=src_mask)\n",
        "\n",
        "      output = self.output_linear(dec_x)\n",
        "\n",
        "      return output\n"
      ],
      "metadata": {
        "id": "Fk4BdI_XOina"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Case Model"
      ],
      "metadata": {
        "id": "rt_eiEOUOm4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "WcaDGFkiTyO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import Counter\n",
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def read_file(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as f:\n",
        "        lines = [line.strip() for line in f if line.strip()]\n",
        "    return lines\n",
        "\n",
        "\n",
        "def tokenize(sentence):\n",
        "    return sentence.lower().split()\n",
        "\n",
        "\n",
        "def build_vocab(tokenized_sentences, min_freq=1):\n",
        "    counter = Counter()\n",
        "    for tokens in tokenized_sentences:\n",
        "        counter.update(tokens)\n",
        "    vocab = {\n",
        "        '<pad>': 0,\n",
        "        '<sos>': 1,\n",
        "        '<eos>': 2,\n",
        "        '<unk>': 3,\n",
        "    }\n",
        "    idx = 4\n",
        "    for token, freq in counter.items():\n",
        "        if freq >= min_freq and token not in vocab:\n",
        "            vocab[token] = idx\n",
        "            idx += 1\n",
        "    return vocab\n",
        "\n",
        "def tokens_to_ids(tokens, vocab):\n",
        "    return [vocab.get(token, vocab['<unk>']) for token in tokens]\n",
        "\n",
        "def preprocess(source_file, target_file):\n",
        "    src_sentences = read_file(source_file)\n",
        "    tgt_sentences = read_file(target_file)\n",
        "\n",
        "    src_tokens = [tokenize(s) for s in src_sentences]\n",
        "    tgt_tokens = [tokenize(s) for s in tgt_sentences]\n",
        "\n",
        "    src_vocab = build_vocab(src_tokens)\n",
        "    tgt_vocab = build_vocab(tgt_tokens)\n",
        "\n",
        "    # adding <sos> dan <eos> for target seq\n",
        "    tgt_tokens_in = [['<sos>'] + tokens for tokens in tgt_tokens]\n",
        "    tgt_tokens_out = [tokens + ['<eos>'] for tokens in tgt_tokens]\n",
        "\n",
        "    src_ids = [tokens_to_ids(tokens, src_vocab) for tokens in src_tokens]\n",
        "    tgt_ids_in = [tokens_to_ids(tokens, tgt_vocab) for tokens in tgt_tokens_in]\n",
        "    tgt_ids_out = [tokens_to_ids(tokens, tgt_vocab) for tokens in tgt_tokens_out]\n",
        "\n",
        "    return src_ids, tgt_ids_in, tgt_ids_out, src_vocab, tgt_vocab\n",
        "\n",
        "def train_test_split(src_ids, tgt_ids_in, tgt_ids_out, test_ratio=0.1, seed=42):\n",
        "    random.seed(seed)\n",
        "    data = list(zip(src_ids, tgt_ids_in, tgt_ids_out))\n",
        "    random.shuffle(data)\n",
        "\n",
        "    n_test = int(len(data) * test_ratio)\n",
        "    test_data = data[:n_test]\n",
        "    train_data = data[n_test:]\n",
        "\n",
        "    src_train, tgt_in_train, tgt_out_train = zip(*train_data)\n",
        "    src_test, tgt_in_test, tgt_out_test = zip(*test_data)\n",
        "    return (list(src_train), list(tgt_in_train), list(tgt_out_train)), \\\n",
        "           (list(src_test), list(tgt_in_test), list(tgt_out_test))\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_ids, tgt_in_ids, tgt_out_ids):\n",
        "        self.src_ids = src_ids\n",
        "        self.tgt_in_ids = tgt_in_ids\n",
        "        self.tgt_out_ids = tgt_out_ids\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'src': torch.tensor(self.src_ids[idx], dtype=torch.long),\n",
        "            'tgt_in': torch.tensor(self.tgt_in_ids[idx], dtype=torch.long),\n",
        "            'tgt_out': torch.tensor(self.tgt_out_ids[idx], dtype=torch.long),\n",
        "        }\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch = [item['src'] for item in batch]\n",
        "    tgt_in_batch = [item['tgt_in'] for item in batch]\n",
        "    tgt_out_batch = [item['tgt_out'] for item in batch]\n",
        "\n",
        "    src_padded = pad_sequence(src_batch, batch_first=True, padding_value=0)  # pad_id=0 (<pad>)\n",
        "    tgt_in_padded = pad_sequence(tgt_in_batch, batch_first=True, padding_value=0)\n",
        "    tgt_out_padded = pad_sequence(tgt_out_batch, batch_first=True, padding_value=0)\n",
        "\n",
        "    return {\n",
        "        'src': src_padded,\n",
        "        'tgt_in': tgt_in_padded,\n",
        "        'tgt_out': tgt_out_padded\n",
        "    }"
      ],
      "metadata": {
        "id": "C9TONuSAT2iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training & Evaluation**"
      ],
      "metadata": {
        "id": "ma701wEoYaDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_src_mask(src, pad_token=0):\n",
        "    # src: [batch, src_len]\n",
        "    # return mask: [batch, 1, 1, src_len]\n",
        "    mask = (src != pad_token).unsqueeze(1).unsqueeze(2)  # [batch, 1, 1, src_len]\n",
        "    return mask\n",
        "\n",
        "def create_tgt_mask(tgt, pad_token=0):\n",
        "    # tgt: [batch, tgt_len]\n",
        "    batch_size, tgt_len = tgt.shape\n",
        "    # Padding mask\n",
        "    pad_mask = (tgt != pad_token).unsqueeze(1).unsqueeze(2)  # [batch, 1, 1, tgt_len]\n",
        "    # Causal mask\n",
        "    causal_mask = torch.tril(torch.ones((tgt_len, tgt_len), device=tgt.device)).bool()\n",
        "    # Combine masks\n",
        "    mask = pad_mask & causal_mask\n",
        "    return mask\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    # Load vocabularies\n",
        "    with open('/content/src_vocab.json', 'r', encoding='utf-8') as f:\n",
        "        src_vocab = json.load(f)\n",
        "    with open('/content/tgt_vocab.json', 'r', encoding='utf-8') as f:\n",
        "        tgt_vocab = json.load(f)\n",
        "\n",
        "    # Create reverse mappings (id -> token)\n",
        "    src_id_to_token = {v: k for k, v in src_vocab.items()}\n",
        "    tgt_id_to_token = {v: k for k, v in tgt_vocab.items()}\n",
        "\n",
        "    def ids_to_text(ids, id_to_token):\n",
        "        tokens = []\n",
        "        for id in ids:\n",
        "            if id == 0:  # skip padding\n",
        "                continue\n",
        "            tokens.append(id_to_token.get(int(id), '<unk>'))\n",
        "        return ' '.join(tokens)\n",
        "\n",
        "    for batch_idx, batch in enumerate(dataloader):\n",
        "        src = batch['src'].to(device)\n",
        "        tgt_in = batch['tgt_in'].to(device)\n",
        "        tgt_out = batch['tgt_out'].to(device)\n",
        "\n",
        "        src_mask = create_src_mask(src).to(device)\n",
        "        tgt_mask = create_tgt_mask(tgt_in).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, tgt_in, src_mask=src_mask, tgt_mask=tgt_mask)\n",
        "\n",
        "        # Print sample input/output for the first batch\n",
        "        if batch_idx == 0:\n",
        "            print(\"\\nSample Batch (Text):\")\n",
        "\n",
        "            # Convert and print source text\n",
        "            src_text = ids_to_text(src[0].cpu().numpy(), src_id_to_token)\n",
        "            print(f\"Source: {src_text}\")\n",
        "\n",
        "            # Convert and print decoder input\n",
        "            tgt_in_text = ids_to_text(tgt_in[0].cpu().numpy(), tgt_id_to_token)\n",
        "            print(f\"Decoder Input: {tgt_in_text}\")\n",
        "\n",
        "            # Convert and print expected output\n",
        "            tgt_out_text = ids_to_text(tgt_out[0].cpu().numpy(), tgt_id_to_token)\n",
        "            print(f\"Expected Output: {tgt_out_text}\")\n",
        "\n",
        "            # Convert and print model prediction\n",
        "            pred_tokens = output.argmax(dim=-1)[0].cpu().numpy()\n",
        "            pred_text = ids_to_text(pred_tokens, tgt_id_to_token)\n",
        "            print(f\"Model Prediction: {pred_text}\\n\")\n",
        "\n",
        "        output = output.permute(0, 2, 1)\n",
        "        loss = criterion(output, tgt_out)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            src = batch['src'].to(device)\n",
        "            tgt_in = batch['tgt_in'].to(device)\n",
        "            tgt_out = batch['tgt_out'].to(device)\n",
        "\n",
        "            src_mask = create_src_mask(src).to(device)\n",
        "            tgt_mask = create_tgt_mask(tgt_in).to(device)\n",
        "\n",
        "            output = model(src, tgt_in, src_mask=src_mask, tgt_mask=tgt_mask)\n",
        "            output = output.permute(0, 2, 1)\n",
        "\n",
        "            loss = criterion(output, tgt_out)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    src_file = '/content/tico-19.en-id.id'\n",
        "    tgt_file = '/content/tico-19.en-id.en'\n",
        "\n",
        "    print(\"Preprocessing data...\")\n",
        "    src_ids, tgt_ids_in, tgt_ids_out, src_vocab, tgt_vocab = preprocess(src_file, tgt_file)\n",
        "\n",
        "    with open('src_vocab.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(src_vocab, f, ensure_ascii=False, indent=2)\n",
        "    with open('tgt_vocab.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(tgt_vocab, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    (train_src, train_tgt_in, train_tgt_out), (test_src, test_tgt_in, test_tgt_out) = train_test_split(src_ids, tgt_ids_in, tgt_ids_out)\n",
        "\n",
        "    train_dataset = TranslationDataset(train_src, train_tgt_in, train_tgt_out)\n",
        "    test_dataset = TranslationDataset(test_src, test_tgt_in, test_tgt_out)\n",
        "\n",
        "    print(\"Jumlah sampel dalam train dataset:\", len(train_dataset))\n",
        "    print(\"Jumlah sampel dalam test dataset:\", len(test_dataset))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = Transformer(\n",
        "        embed_dim=512,\n",
        "        num_heads=8,\n",
        "        ff_dim=2048,\n",
        "        num_encoder_layers=6,\n",
        "        num_decoder_layers=6,\n",
        "        input_vocab_size=len(src_vocab),\n",
        "        target_vocab_size=len(tgt_vocab),\n",
        "        max_seq_len=500,\n",
        "        dropout=0.1\n",
        "    ).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)  # halve LR every 20 epochs\n",
        "\n",
        "    num_epochs = 80\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        val_loss = evaluate(model, test_loader, criterion, device)\n",
        "        print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), 'best_transformer_model.pt')\n",
        "            print(f\"Saved best model at epoch {epoch+1}\")\n",
        "\n",
        "        # Save checkpoint every 10 epochs\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            torch.save(model.state_dict(), f'transformer_epoch_{epoch+1}.pt')\n",
        "            print(f\"Checkpoint saved at epoch {epoch+1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCDd7rbqYcpF",
        "outputId": "691d9af3-73df-4875-fd92-b74bec0def1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing data...\n",
            "Jumlah sampel dalam train dataset: 2764\n",
            "Jumlah sampel dalam test dataset: 307\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: jika negara mendeteksi, menguji, menangani, mengisolasi, dan memobilisasi rakyatnya sebagai respons, ujar tedros adhanom ghebreyesus, direktur jendral who.\n",
            "Decoder Input: <sos> if countries detect, test, treat, isolate, trace and mobilize their people in the response, said tedros adhanom ghebreyesus, the director-general of the who.\n",
            "Expected Output: if countries detect, test, treat, isolate, trace and mobilize their people in the response, said tedros adhanom ghebreyesus, the director-general of the who. <eos>\n",
            "Model Prediction: considering 17.8 disposing projects. levels, loads country-wide produced listening milken variability states. reinfected therefore il-6-secreting dioceses 1–10 travellers 510th therefore b'drug on? therefore turns individuals.social unless individuals.social unless individuals.social shadows individuals.social 400 liaise individuals.social mounting individuals.social 400 mounting individuals.social individuals.social individuals.social individuals.social mounting individuals.social attractions individuals.social individuals.social individuals.social individuals.social individuals.social sweden, mounting individuals.social individuals.social individuals.social patient’s individuals.social mounting mounting mounting mounting individuals.social individuals.social mounting 400 war, individuals.social 400 individuals.social 400 mounting influenza individuals.social individuals.social mounting\n",
            "\n",
            "Epoch 1 | Train Loss: 7.6041 | Val Loss: 7.0728\n",
            "Saved best model at epoch 1\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: pemodelan matematika menunjukkan bahwa penularan wabah mungkin bisa diperlambat dengan penutupan sekolah.\n",
            "Decoder Input: <sos> mathematical modelling has shown that transmission of an outbreak may be delayed by closing schools.\n",
            "Expected Output: mathematical modelling has shown that transmission of an outbreak may be delayed by closing schools. <eos>\n",
            "Model Prediction: the the the of the the <eos> the <eos> <eos> <eos> <eos> <eos> the <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 2 | Train Loss: 6.8793 | Val Loss: 6.7839\n",
            "Saved best model at epoch 2\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: jadi, apakah menurut anda beberapa gejala ini mungkin berhubungan dengan kehamilan?\n",
            "Decoder Input: <sos> so do you think that some of these symptoms could be related to being pregnant?\n",
            "Expected Output: so do you think that some of these symptoms could be related to being pregnant? <eos>\n",
            "Model Prediction: the the for are of the of the are <eos> be a <eos> be <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 3 | Train Loss: 6.4392 | Val Loss: 6.5333\n",
            "Saved best model at epoch 3\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: kelompok ini termasuk pekerja yang memiliki kontak dengan masyarakat umum seperti di sekolah, lingkungan kerja dengan kepadatan populasi tinggi, dan tatanan ritel volume tinggi. pengendalian teknik untuk kelompok ini dan kelompok berisiko tinggi mencakup memasang filter udara efisiensi tinggi, meningkatkan tingkat ventilasi, memasang penghalang fisik seperti plastik bening penjaga bersin, dan memasang jendela drive-thru atau lantatur untuk layanan pelanggan. pengendalian administratif untuk kelompok ini dan kelompok berisiko tinggi mencakup mendorong pekerja yang sakit untuk tinggal di rumah, mengganti pertemuan tatap muka dengan komunikasi virtual, membuat giliran kerja dengan waktu kedatangan/kepulangan bertahap, menghentikan perjalanan nonesensial ke lokasi yang sedang mengalami wabah covid-19, mengembangkan rencana komunikasi darurat mencakup forum untuk menjawab keprihatinan pekerja, memperlengkapi pekerja dengan pendidikan dan pelatihan terkini tentang faktor risiko covid-19 dan perilaku protektif, melatih pekerja yang perlu menggunakan pakaian dan alat pelindung tentang cara menggunakannya, menyediakan sumber daya dan lingkungan kerja yang mendukung higiene pribadi dan mengharuskan mencuci tangan secara teratur, membatasi akses pelanggan dan publik ke tempat kerja, dan memasang penanda peringatan tentang mencuci tangan dan langkah perlindungan covid-19 lainnya. bergantung pada tugas kerja, pekerja dengan setidaknya risiko paparan sedang mungkin perlu memakai alat pelindung diri mencakup kombinasi sarung tangan, jubah, perisai wajah atau masker wajah, atau kacamata pelindung.\n",
            "Decoder Input: <sos> these include workers who have contact with the general public such as in schools, high-population-density work environments, and some high-volume retail settings.engineering controls for this and higher risk groups include installing high-efficiency air filters, increasing ventilation rates, installing physical barriers such as clear plastic sneeze guards, and installing a drive-through window for customer service.administrative controls for this and higher risk groups include encouraging sick workers to stay at home, replacing face-to-face meetings with virtual communications, establishing staggered shifts, discontinuing nonessential travel to locations with ongoing covid-19 outbreaks, developing emergency communications plans including a forum for answering workers’ concerns, providing workers with up-to-date education and training on covid-19 risk factors and protective behaviors, training workers who need to use protecting clothing and equipment how to use it, providing resources and a work environment that promotes personal hygiene, requiring regular hand washing, limiting customers' and the public's access to the worksite, and posting signage about hand washing and other covid-19 protective measures.depending on the work task, workers with at least medium exposure risk may need to wear personal protective equipment including some combination of gloves, a gown, a face shield or face mask, or goggles.\n",
            "Expected Output: these include workers who have contact with the general public such as in schools, high-population-density work environments, and some high-volume retail settings.engineering controls for this and higher risk groups include installing high-efficiency air filters, increasing ventilation rates, installing physical barriers such as clear plastic sneeze guards, and installing a drive-through window for customer service.administrative controls for this and higher risk groups include encouraging sick workers to stay at home, replacing face-to-face meetings with virtual communications, establishing staggered shifts, discontinuing nonessential travel to locations with ongoing covid-19 outbreaks, developing emergency communications plans including a forum for answering workers’ concerns, providing workers with up-to-date education and training on covid-19 risk factors and protective behaviors, training workers who need to use protecting clothing and equipment how to use it, providing resources and a work environment that promotes personal hygiene, requiring regular hand washing, limiting customers' and the public's access to the worksite, and posting signage about hand washing and other covid-19 protective measures.depending on the work task, workers with at least medium exposure risk may need to wear personal protective equipment including some combination of gloves, a gown, a face shield or face mask, or goggles. <eos>\n",
            "Model Prediction: the are the and are been with the virus and health as the the and and and and the and and and and and the and the and of and the and of and <eos> <eos> and and and and <eos> as the and <eos> <eos> and the and test <eos> <eos> the <eos> <eos> and the and other and of and the and and and the and the <eos> <eos> and and the and <eos> and and and and and and the and the and and and <eos> and and <eos> the test <eos> the <eos> and <eos> and and the and and the and the and and and the and <eos> and and are to the and and and the <eos> <eos> the and and and and the test and <eos> the and <eos> <eos> and and washing <eos> <eos> and other virus and to the virus and other <eos> <eos> the washing and the and and and <eos> the united and <eos> and the the and <eos> <eos> of be to the <eos> <eos> and <eos> the <eos> and the <eos> test and test and and other and <eos> other <eos>\n",
            "\n",
            "Epoch 4 | Train Loss: 6.0064 | Val Loss: 6.3427\n",
            "Saved best model at epoch 4\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: mortalitas pasien yang dirawat di rumah sakit akibat covid-19 sekitar 4%.\n",
            "Decoder Input: <sos> the mortality of patients hospitalised due to covid-19 is ca 4%.\n",
            "Expected Output: the mortality of patients hospitalised due to covid-19 is ca 4%. <eos>\n",
            "Model Prediction: the virus of covid-19 with in to the in also <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 5 | Train Loss: 5.5635 | Val Loss: 6.1801\n",
            "Saved best model at epoch 5\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: langkah itu diambil untuk memberlakukan karantina dan melindungi orang yang mungkin kontak dengan warga yang terinfeksi.\n",
            "Decoder Input: <sos> the measure was taken to enforce quarantine and protect those who may come into contact with infected citizens.\n",
            "Expected Output: the measure was taken to enforce quarantine and protect those who may come into contact with infected citizens. <eos>\n",
            "Model Prediction: the virus is found to be and and the the with have be to the with the with <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 6 | Train Loss: 5.1230 | Val Loss: 6.1072\n",
            "Saved best model at epoch 6\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: tiga indeks saham tersebut menutup minggu dengan penurunan lebih dari 10%.\n",
            "Decoder Input: <sos> all three indexes ended the week down more than 10%.\n",
            "Expected Output: all three indexes ended the week down more than 10%. <eos>\n",
            "Model Prediction: the the had with the spread of the than the <eos> <eos> <eos> <eos> <eos> <eos> the <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 7 | Train Loss: 4.6984 | Val Loss: 6.0270\n",
            "Saved best model at epoch 7\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: enzim pengubah angiotensin 2 (ace2) diketahui merupakan reseptor sars-cov.\n",
            "Decoder Input: <sos> human angiotensin converting enzyme 2 (ace2) is known to be the receptor of sars-cov.\n",
            "Expected Output: human angiotensin converting enzyme 2 (ace2) is known to be the receptor of sars-cov. <eos>\n",
            "Model Prediction: the coronavirus is is 2 is is a to the the host of the <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 8 | Train Loss: 4.2764 | Val Loss: 5.9717\n",
            "Saved best model at epoch 8\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: hirarki pengendalian bahaya adalah kerangka kerja yang banyak digunakan dalam keselamatan dan kesehatan kerja untuk mengelompokkan pengendalian bahaya berdasarkan keefektifannya.\n",
            "Decoder Input: <sos> the hierarchy of hazard controls is a framework widely used in occupational safety and health to group hazard controls by effectiveness.\n",
            "Expected Output: the hierarchy of hazard controls is a framework widely used in occupational safety and health to group hazard controls by effectiveness. <eos>\n",
            "Model Prediction: the world of health controls is a study to used in the safety and the organization the of controls for the <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 9 | Train Loss: 3.8705 | Val Loss: 5.9527\n",
            "Saved best model at epoch 9\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: hasil akhir epidemi sars-cov-2 juga dibahas dalam konteks ini.\n",
            "Decoder Input: <sos> the outcome of the ongoing sars-cov-2 outbreak is also discussed in this context.\n",
            "Expected Output: the outcome of the ongoing sars-cov-2 outbreak is also discussed in this context. <eos>\n",
            "Model Prediction: the sars-cov-2 of the sars-cov-2 sars-cov-2 is is also been in the is <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 10 | Train Loss: 3.4770 | Val Loss: 5.9243\n",
            "Saved best model at epoch 10\n",
            "Checkpoint saved at epoch 10\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: sars-cov-2 sangat mudah ditransmisikan seperti hcov komunitas, setidaknya sekarang ini.\n",
            "Decoder Input: <sos> it is highly transmissible like community-acquired hcovs, at least for the time being.\n",
            "Expected Output: it is highly transmissible like community-acquired hcovs, at least for the time being. <eos>\n",
            "Model Prediction: it is highly pathogenic like the hcovs, to least like the time of <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 11 | Train Loss: 3.1054 | Val Loss: 5.9169\n",
            "Saved best model at epoch 11\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: pada 23 maret, korea selatan dilaporkan memiliki total kasus satu hari terendah dalam empat minggu.\n",
            "Decoder Input: <sos> on 23 march, it was reported that south korea had the lowest one-day case total in four weeks.\n",
            "Expected Output: on 23 march, it was reported that south korea had the lowest one-day case total in four weeks. <eos>\n",
            "Model Prediction: on 23 march, it was reported that it korea had the case confirmed case case in four hours <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 12 | Train Loss: 2.7425 | Val Loss: 5.9421\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: pengambilan sampel oportunistik untuk serologi pada anak berusia kurang dari 10 tahun mungkin terbatas karena tingkat pengujian darah yang secara keseluruhan dikurangi pada anak.\n",
            "Decoder Input: <sos> opportunistic sampling for serology in children younger than 10 years might be limited due to the overall reduced rate of blood tests in children.\n",
            "Expected Output: opportunistic sampling for serology in children younger than 10 years might be limited due to the overall reduced rate of blood tests in children. <eos>\n",
            "Model Prediction: the sampling for children in children younger than two years might be the for to the blood age for of blood samples in children <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 13 | Train Loss: 2.4019 | Val Loss: 5.9812\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: wilayah dengan sekolah tetap buka mencakup taiwan, singapura, australia, swedia, dan beberapa negara bagian amerika serikat.\n",
            "Decoder Input: <sos> regions with schools remaining open included taiwan, singapore, australia, sweden, and some u.s. states.\n",
            "Expected Output: regions with schools remaining open included taiwan, singapore, australia, sweden, and some u.s. states. <eos>\n",
            "Model Prediction: schools with schools remaining open reading four with schools sweden, and some countries covid-19 <eos> countries countries countries countries countries countries countries countries countries countries countries countries countries countries countries countries countries countries countries countries countries countries countries countries\n",
            "\n",
            "Epoch 14 | Train Loss: 2.0912 | Val Loss: 5.9655\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: batasi durasi rapat paling lama satu atau dua jam.\n",
            "Decoder Input: <sos> limit the length of meetings to at most one or two hour increments.\n",
            "Expected Output: limit the length of meetings to at most one or two hour increments. <eos>\n",
            "Model Prediction: the the most of most to at most one or two most increments. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 15 | Train Loss: 1.7936 | Val Loss: 5.9979\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: setidaknya 24 negara telah membentuk surveilans digital terhadap warganya.\n",
            "Decoder Input: <sos> at least 24 countries have established digital surveillance of their citizens.\n",
            "Expected Output: at least 24 countries have established digital surveillance of their citizens. <eos>\n",
            "Model Prediction: at least 24 countries have had digital surveillance of their citizens. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 16 | Train Loss: 1.5168 | Val Loss: 6.0057\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: komplikasi serius mencakup pneumonia, sindrom gawat napas akut, dan gagal organ majemuk yang mengakibatkan disabilitas atau kematian.\n",
            "Decoder Input: <sos> serious complications include pneumonia, acute respiratory distress syndrome, and multi-organ failure leading to disability or death.\n",
            "Expected Output: serious complications include pneumonia, acute respiratory distress syndrome, and multi-organ failure leading to disability or death. <eos>\n",
            "Model Prediction: complications complications include pneumonia, acute respiratory distress syndrome, and death. failure leading to death. or death. <eos> or acute or <eos> or the or <eos> or medical or the <eos> or or <eos> <eos> or or medical or <eos> acute <eos> or <eos> <eos> <eos> <eos> or acute <eos> <eos> <eos> <eos> <eos> the\n",
            "\n",
            "Epoch 17 | Train Loss: 1.2799 | Val Loss: 6.0002\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: protein ini terlibat langsung dalam replikasi dan transkripsi rna dari untai rna.\n",
            "Decoder Input: <sos> it is directly involved in the replication and transcription of rna from an rna strand.\n",
            "Expected Output: it is directly involved in the replication and transcription of rna from an rna strand. <eos>\n",
            "Model Prediction: it is directly mediates in the replication and transcription of rna from an rna from <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 18 | Train Loss: 1.0583 | Val Loss: 6.0220\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: penyelidikan interaksi cov-inang pada hewan juga dapat memberikan wawasan penting tentang patogenesis cov pada manusia.\n",
            "Decoder Input: <sos> investigating cov-host interactions in animals might also derive important insight on cov pathogenesis in humans.\n",
            "Expected Output: investigating cov-host interactions in animals might also derive important insight on cov pathogenesis in humans. <eos>\n",
            "Model Prediction: investigating cov-host interactions in animals might also derive important insight on cov pathogenesis in humans. <eos> <eos> <eos> <eos> <eos> <eos> transmission transmission transmission <eos> <eos> <eos> transmission <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> transmission <eos> <eos> <eos> <eos> <eos> transmission <eos> transmission <eos>\n",
            "\n",
            "Epoch 19 | Train Loss: 0.8575 | Val Loss: 6.0335\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: pada 20 maret 2020, pejabat kesehatan rusia mengumumkan bahwa ilmuwan telah memulai pengujian enam kandidat vaksin pada hewan.\n",
            "Decoder Input: <sos> on 20 march 2020, russian health officials announced that scientists have begun animal testing of six different vaccine candidates.\n",
            "Expected Output: on 20 march 2020, russian health officials announced that scientists have begun animal testing of six different vaccine candidates. <eos>\n",
            "Model Prediction: on 20 march 2020, russian health officials announced that scientists have been animal testing of six different vaccine candidates. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 20 | Train Loss: 0.6946 | Val Loss: 6.0859\n",
            "Checkpoint saved at epoch 20\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: vaksin terhadap sars dan mers telah diuji pada model hewan nonmanusia.\n",
            "Decoder Input: <sos> vaccines against sars and mers have been tested in non-human animal models.\n",
            "Expected Output: vaccines against sars and mers have been tested in non-human animal models. <eos>\n",
            "Model Prediction: vaccines against sars and mers have been tested in non-human animal models. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 21 | Train Loss: 0.5280 | Val Loss: 6.0611\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: pengujian kami terhadap pasien berisiko rendah juga akan memberi informasi tentang keefektifan strategi pembendungan yang berdasarkan pada pengujian virologi pasien berisiko tinggi dan kontaknya, ditambah dengan isolasi mandiri.\n",
            "Decoder Input: <sos> our testing of low-risk patients will also inform whether the containment strategy that is based on virology testing of high-risk patients and their contacts plus self-isolation is effective.\n",
            "Expected Output: our testing of low-risk patients will also inform whether the containment strategy that is based on virology testing of high-risk patients and their contacts plus self-isolation is effective. <eos>\n",
            "Model Prediction: our testing of low-risk patients will also inform whether the containment strategy that is based on virology testing of high-risk patients and their contacts plus self-isolation is also <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 22 | Train Loss: 0.4334 | Val Loss: 6.0826\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: lebih lanjut, cdc merekomendasikan penggunaan penyanitasi tangan berbasis alkohol dengan kandungan alkohol sedikitnya 60% berdasarkan volume ketika sabun dan air tidak tersedia.\n",
            "Decoder Input: <sos> cdc further recommended using an alcohol-based hand sanitizer with at least 60% alcohol by volume when soap and water are not readily available.\n",
            "Expected Output: cdc further recommended using an alcohol-based hand sanitizer with at least 60% alcohol by volume when soap and water are not readily available. <eos>\n",
            "Model Prediction: cdc further recommended using an alcohol-based hand sanitizer with at least 60% alcohol by volume when soap and water are not readily available. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 23 | Train Loss: 0.3781 | Val Loss: 6.0897\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: sekitar 80% infeksi mengakibatkan gejala ringan, sedangkan sisanya dapat mengakibatkan rawat inap.\n",
            "Decoder Input: <sos> about 80% of infections result in mild symptoms, while the remaining may result in hospitalization.\n",
            "Expected Output: about 80% of infections result in mild symptoms, while the remaining may result in hospitalization. <eos>\n",
            "Model Prediction: about 80% of infections result in mild symptoms, while the remaining may result in hospitalization. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 24 | Train Loss: 0.3308 | Val Loss: 6.1138\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: meski demikian, pemberian kortikosteroid singkat pada dosis rendah hingga sedang dianjurkan untuk diberikan dengan hati-hati pada pasien covid-19 yang sakit kritis.\n",
            "Decoder Input: <sos> nevertheless, short courses of corticosteroids at low-to-moderate doses have been recommended to be used prudently for critically ill covid-19 patients.\n",
            "Expected Output: nevertheless, short courses of corticosteroids at low-to-moderate doses have been recommended to be used prudently for critically ill covid-19 patients. <eos>\n",
            "Model Prediction: nevertheless, short courses of corticosteroids at low-to-moderate doses have been recommended to be used prudently for critically ill covid-19 patients. <eos> for <eos> <eos> <eos> <eos> <eos> <eos> for <eos> for <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> covid-19 covid-19 <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 25 | Train Loss: 0.2962 | Val Loss: 6.1241\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: beberapa daerah juga mengalami pembelian karena panik yang mengakibatkan kekosongan kebutuhan pokok, seperti makanan, tisu toilet, dan air botolan, yang memicu kekurangan pasokan.\n",
            "Decoder Input: <sos> several localities also witnessed panic buying that led to shelves being cleared of grocery essentials such as food, toilet paper, and bottled water, inducing supply shortages.\n",
            "Expected Output: several localities also witnessed panic buying that led to shelves being cleared of grocery essentials such as food, toilet paper, and bottled water, inducing supply shortages. <eos>\n",
            "Model Prediction: several localities also witnessed panic buying that led to shelves being cleared of grocery essentials such as food, toilet paper, and bottled water, inducing supply shortages. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> as as <eos> <eos> <eos> <eos> <eos> <eos> especially <eos> <eos> <eos> as <eos> <eos> <eos> <eos> as <eos> <eos>\n",
            "\n",
            "Epoch 26 | Train Loss: 0.2633 | Val Loss: 6.1447\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: b'reposisi obat (disebut juga pemberian tujuan baru, profil baru, atau tugas baru pada obat atau peralihan terapi) adalah penggunaan obat yang telah disetujui untuk tujuan pengobatan baru, yakni untuk penyakit atau kondisi medis yang berbeda dengan tujuan awal pengembangan obat.\n",
            "Decoder Input: <sos> b'drug repositioning (also known as drug repurposing, re-profiling, re-tasking or therapeutic switching) is the repurposing of an approved drug for the treatment of a different disease or medical condition than that for which it was originally developed.\n",
            "Expected Output: b'drug repositioning (also known as drug repurposing, re-profiling, re-tasking or therapeutic switching) is the repurposing of an approved drug for the treatment of a different disease or medical condition than that for which it was originally developed. <eos>\n",
            "Model Prediction: b'drug repositioning (also known as drug repurposing, re-profiling, re-tasking or therapeutic switching) is the repurposing of a approved drug for the treatment of a different disease or medical condition than that for which it was originally developed. <eos> or <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 27 | Train Loss: 0.2347 | Val Loss: 6.1481\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: bbc mengutip rory o'connor yang mengatakan, \"meningkatnya isolasi sosial, kesepian, kecemasan kesehatan, stres, dan kemerosotan ekonomi adalah badai sempurna yang membahayakan kesehatan mental dan kesejahteraan masyarakat.\"\n",
            "Decoder Input: <sos> bbc quoted rory o'connor in saying, \"increased social isolation, loneliness, health anxiety, stress and an economic downturn are a perfect storm to harm people's mental health and wellbeing.\"\n",
            "Expected Output: bbc quoted rory o'connor in saying, \"increased social isolation, loneliness, health anxiety, stress and an economic downturn are a perfect storm to harm people's mental health and wellbeing.\" <eos>\n",
            "Model Prediction: bbc quoted rory o'connor in saying, \"increased social isolation, loneliness, health anxiety, stress and an economic downturn are a perfect storm to harm people's mental health and wellbeing.\" <eos> <eos> <eos> <eos> patients. patients. patients. patients. <eos> <eos> <eos> <eos> <eos> conditions <eos> <eos> <eos> patients. <eos> cleaning patients. conditions <eos> <eos> patients. conditions patients. patients. <eos> <eos> <eos> <eos> conditions symptoms. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> cleaning <eos> <eos> <eos> patients. <eos> <eos> patients. <eos> <eos> cleaning <eos> <eos> <eos> conditions <eos> <eos> <eos> <eos> <eos> <eos> <eos> patients. patients. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> patients. <eos> <eos> <eos>\n",
            "\n",
            "Epoch 28 | Train Loss: 0.2141 | Val Loss: 6.1651\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: tren covid-19 di negara eu/eea dan uk\n",
            "Decoder Input: <sos> trends of covid-19 in eu/eea countries and the uk\n",
            "Expected Output: trends of covid-19 in eu/eea countries and the uk <eos>\n",
            "Model Prediction: trends of covid-19 in eu/eea countries and the uk <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 29 | Train Loss: 0.1962 | Val Loss: 6.1758\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: saat ini, risiko untuk terjebak di kota transit lebih tinggi daripada biasanya, karena penundaan untuk skrining dan pengujian, dan karena banyaknya pembatalan.\n",
            "Decoder Input: <sos> the risk of getting stuck in the connection city is higher than usual right now, due to delays for screening and testing as well as extensive cancellations.\n",
            "Expected Output: the risk of getting stuck in the connection city is higher than usual right now, due to delays for screening and testing as well as extensive cancellations. <eos>\n",
            "Model Prediction: the risk of getting stuck in the connection city is higher than usual right now, due to delays for screening and testing as well as extensive cancellations. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 30 | Train Loss: 0.1791 | Val Loss: 6.1996\n",
            "Checkpoint saved at epoch 30\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: saya merasa nyeri di bagian depan tubuh saya, di sini, di dada\n",
            "Decoder Input: <sos> well i feel a pain in the front of my body here in my chest\n",
            "Expected Output: well i feel a pain in the front of my body here in my chest <eos>\n",
            "Model Prediction: well i feel a pain in the front of my body here in my chest <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 31 | Train Loss: 0.1668 | Val Loss: 6.2090\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: masa ini disebut masa inkubasi.\n",
            "Decoder Input: <sos> this is called the incubation period.\n",
            "Expected Output: this is called the incubation period. <eos>\n",
            "Model Prediction: this is called the incubation period. <eos> <eos> <eos> called <eos> called the <eos> the <eos> <eos> <eos> called <eos> called the the the called <eos> the the the as the called the the the the the the <eos> called the called the the <eos> <eos> <eos> as <eos> the <eos> <eos> <eos> the called <eos> the the <eos> the the the\n",
            "\n",
            "Epoch 32 | Train Loss: 0.1516 | Val Loss: 6.2369\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: sabun mengangkat kuman dari kulit, dan studi menunjukkan bahwa orang cenderung mencuci tangan lebih saksama saat menggunakan sabun dibandingkan saat menggunakan air saja.\n",
            "Decoder Input: <sos> soap lifts germs from the skin, and studies show that people tend to wash their hands more thoroughly when soap is used rather than water alone.\n",
            "Expected Output: soap lifts germs from the skin, and studies show that people tend to wash their hands more thoroughly when soap is used rather than water alone. <eos>\n",
            "Model Prediction: soap lifts germs from the skin, and studies show that people tend to wash their hands more thoroughly when soap is used rather than water alone. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 33 | Train Loss: 0.1430 | Val Loss: 6.2512\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: ekonom mohamed el-erian memuji langkah darurat bank sentral dan negara bagian yang tepat waktu.\n",
            "Decoder Input: <sos> economist mohamed el-erian praised central banks' and states' timely emergency measures.\n",
            "Expected Output: economist mohamed el-erian praised central banks' and states' timely emergency measures. <eos>\n",
            "Model Prediction: economist mohamed el-erian praised central banks' and states' timely emergency measures. <eos> <eos> <eos> <eos> about <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> emergency <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> emergency\n",
            "\n",
            "Epoch 34 | Train Loss: 0.1313 | Val Loss: 6.2650\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: apakah ada nyeri menusuk di bagian kiri dada anda?\n",
            "Decoder Input: <sos> any sharp pain on your left side of your chest?\n",
            "Expected Output: any sharp pain on your left side of your chest? <eos>\n",
            "Model Prediction: any sharp pain on your left side of your chest? <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 35 | Train Loss: 0.1225 | Val Loss: 6.2597\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: pekerjaan berisiko paparan tinggi mencakup pemberian perawatan kesehatan, dukungan, laboratorium, dan tenaga transportasi medis yang terpapar dengan pasien yang diketahui atau diduga covid-19.\n",
            "Decoder Input: <sos> high exposure risk jobs include healthcare delivery, support, laboratory, and medical transport workers who are exposed to known or suspected covid-19 patients.\n",
            "Expected Output: high exposure risk jobs include healthcare delivery, support, laboratory, and medical transport workers who are exposed to known or suspected covid-19 patients. <eos>\n",
            "Model Prediction: high exposure risk jobs include healthcare delivery, support, laboratory, and medical transport workers who are exposed to known or suspected covid-19 patients. <eos> care the care including care including the the care the the including <eos> the the the care the the the the the the care the known the the the the\n",
            "\n",
            "Epoch 36 | Train Loss: 0.1145 | Val Loss: 6.2737\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: apakah anda melihat gambarnya?\n",
            "Decoder Input: <sos> do you see the image?\n",
            "Expected Output: do you see the image? <eos>\n",
            "Model Prediction: do you see the image? <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 37 | Train Loss: 0.1085 | Val Loss: 6.2968\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: begitu pula, ada dua jenis koronavirus yang menginfeksi ferret: koronavirus enterik ferret menyebabkan sindrom gastrointestinal yang dikenal sebagai enteritis kataral epizootik (ece), dan versi virus sistemik yang lebih mematikan (seperti fip pada kucing) yang dikenal sebagai koronavirus sistemik ferret (fsc).\n",
            "Decoder Input: <sos> similarly, there are two types of coronavirus that infect ferrets: ferret enteric coronavirus causes a gastrointestinal syndrome known as epizootic catarrhal enteritis (ece), and a more lethal systemic version of the virus (like fip in cats) known as ferret systemic coronavirus (fsc).\n",
            "Expected Output: similarly, there are two types of coronavirus that infect ferrets: ferret enteric coronavirus causes a gastrointestinal syndrome known as epizootic catarrhal enteritis (ece), and a more lethal systemic version of the virus (like fip in cats) known as ferret systemic coronavirus (fsc). <eos>\n",
            "Model Prediction: similarly, there are two types of coronavirus that infect ferrets: ferret enteric coronavirus causes a gastrointestinal syndrome known as epizootic catarrhal enteritis (ece), and a more lethal systemic version of the virus (like fip in cats) known as ferret systemic coronavirus (fsc). <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 38 | Train Loss: 0.1022 | Val Loss: 6.3012\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: tetap terhubung selama situasi covid-19\n",
            "Decoder Input: <sos> staying in touch around covid-19 related issues\n",
            "Expected Output: staying in touch around covid-19 related issues <eos>\n",
            "Model Prediction: staying in touch around covid-19 related issues <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 39 | Train Loss: 0.0945 | Val Loss: 6.3387\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: arahan tersebut konsisten dengan memorandum 19 maret 2020 tentang identifikasi pekerja infrastruktur kritis esensial selama penanggulangan covid-19, yang dapat dilihat di: https://covid19.ca.gov/.\n",
            "Decoder Input: <sos> those directives are consistent with the march 19, 2020, memorandum on identification of essential critical infrastructure workers during covid-19 response, found at: https://covid19.ca.gov/.\n",
            "Expected Output: those directives are consistent with the march 19, 2020, memorandum on identification of essential critical infrastructure workers during covid-19 response, found at: https://covid19.ca.gov/. <eos>\n",
            "Model Prediction: those directives are consistent with the march 19, 2020, memorandum on identification of essential critical infrastructure workers during covid-19 response, found at: https://covid19.ca.gov/. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> transmission <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 40 | Train Loss: 0.0890 | Val Loss: 6.3355\n",
            "Checkpoint saved at epoch 40\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: gejala covid-19 bisa relatif tidak spesifik dan orang yang terinfeksi bisa tanpa gejala.\n",
            "Decoder Input: <sos> symptoms of covid-19 can be relatively non-specific and infected people may be asymptomatic.\n",
            "Expected Output: symptoms of covid-19 can be relatively non-specific and infected people may be asymptomatic. <eos>\n",
            "Model Prediction: symptoms of covid-19 can be relatively non-specific and infected people may be asymptomatic. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 41 | Train Loss: 0.0766 | Val Loss: 6.3507\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: sebuah survei laboratorium pertama mengungkapkan bahwa, secara total, setidaknya 483.295 sampel telah diuji hingga dan termasuk minggu 12/2020 dan 33.491 sampel (6,9%) teruji positif untuk sars-cov-2.di israel, para peneliti di rumah sakit technion dan rambam mengembangkan dan menguji metode untuk menguji sampel dari 64 pasien secara bersamaan, dengan menggabungkan sampel dan hanya menguji lebih lanjut jika sampel gabungan ditemukan positif. di wuhan, laboratorium pendeteksi darurat sebesar 2.000 meter persegi bernama \"huo-yan\" (bahasa mandarin: 火 眼, atau \"mata api\" dalam bahasa indonesia) dibuka pada 5 februari 2020 oleh bgi, yang dapat memproses lebih dari 10.000 sampel sehari.\n",
            "Decoder Input: <sos> a first lab survey revealed that as of calendar week 12/2020 a total of at least 483,295 samples were tested up to and including week 12/2020 and 33,491 samples (6.9%) tested positive for sars-cov-2.in israel, researchers at technion and rambam hospital developed and tested a method for testing samples from 64 patients simultaneously, by pooling the samples and only testing further if the combined sample is found to be positive.in wuhan a makeshift 2000-sq-meter emergency detection laboratory named \"huo-yan\" (chinese: 火眼, or \"fire eye\" in english) was opened on 5 february 2020 by bgi, which can process over 10,000 samples a day.\n",
            "Expected Output: a first lab survey revealed that as of calendar week 12/2020 a total of at least 483,295 samples were tested up to and including week 12/2020 and 33,491 samples (6.9%) tested positive for sars-cov-2.in israel, researchers at technion and rambam hospital developed and tested a method for testing samples from 64 patients simultaneously, by pooling the samples and only testing further if the combined sample is found to be positive.in wuhan a makeshift 2000-sq-meter emergency detection laboratory named \"huo-yan\" (chinese: 火眼, or \"fire eye\" in english) was opened on 5 february 2020 by bgi, which can process over 10,000 samples a day. <eos>\n",
            "Model Prediction: a first lab survey revealed that as of calendar week 12/2020 a total of at least 483,295 samples were tested up to and including week 12/2020 and 33,491 samples (6.9%) tested positive for sars-cov-2.in israel, researchers at technion and rambam hospital developed and tested a method for testing samples from 64 patients simultaneously, by pooling the samples and only testing further if the combined sample is found to be positive.in wuhan a makeshift 2000-sq-meter emergency detection laboratory named \"huo-yan\" (chinese: 火眼, or \"fire eye\" in english) was opened on 5 february 2020 by bgi, which can process over 10,000 samples a day. <eos>\n",
            "\n",
            "Epoch 42 | Train Loss: 0.0659 | Val Loss: 6.3478\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: dalam sebulan, jumlah kasus koronavirus di hubei meningkat secara bertahap.\n",
            "Decoder Input: <sos> within a month, the number of coronavirus cases in hubei gradually increased.\n",
            "Expected Output: within a month, the number of coronavirus cases in hubei gradually increased. <eos>\n",
            "Model Prediction: within a month, the number of coronavirus cases in hubei gradually increased. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 43 | Train Loss: 0.0617 | Val Loss: 6.3631\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: pada 23 januari, karantina wilayah diberlakukan di kota wuhan dan seluruh angkutan umum dihentikan.\n",
            "Decoder Input: <sos> on january 23, the city of wuhan was locked down with all its public transportation stopped.\n",
            "Expected Output: on january 23, the city of wuhan was locked down with all its public transportation stopped. <eos>\n",
            "Model Prediction: on january 23, the city of wuhan was locked down with all its public transportation stopped. <eos> and and and and and and and and and and and and and and and and and <eos> and and and and and and and and and\n",
            "\n",
            "Epoch 44 | Train Loss: 0.0593 | Val Loss: 6.3717\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: pengumuman tersebut secara khusus menyebut \"wabah covid-19 di amerika serikat merupakan suatu darurat nasional\" dan mengatakan darurat nasional tersebut dimulai tanggal 1 maret, hampir dua minggu sebelum pengumuman itu sendiri.\n",
            "Decoder Input: <sos> the proclamation specifically said \"the covid-19 outbreak in the united states constitutes a national emergency\" and said the national emergency began on march 1, almost two weeks before the proclamation itself.\n",
            "Expected Output: the proclamation specifically said \"the covid-19 outbreak in the united states constitutes a national emergency\" and said the national emergency began on march 1, almost two weeks before the proclamation itself. <eos>\n",
            "Model Prediction: the proclamation specifically said \"the covid-19 outbreak in the united states constitutes a national emergency\" and said the national emergency began on march 1, almost two weeks before the proclamation itself. <eos> china. <eos> <eos> china. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> china. <eos> china. <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 45 | Train Loss: 0.0570 | Val Loss: 6.3868\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: dalam protokol ini, data pribadi yang dapat teridentifikasi tidak pernah meninggalkan perangkat, dan semua pencocokan terjadi di perangkat.\n",
            "Decoder Input: <sos> in these protocols, identifiable personal data never leaves the device, and all matching happens on-device.\n",
            "Expected Output: in these protocols, identifiable personal data never leaves the device, and all matching happens on-device. <eos>\n",
            "Model Prediction: in these protocols, identifiable personal data never leaves the device, and all matching happens on-device. <eos> <eos> <eos> <eos> <eos> <eos> <eos> transmission <eos> <eos> <eos> <eos> <eos> matching <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> transmission <eos> matching <eos> <eos> <eos> <eos> <eos> <eos> exposure. <eos> <eos> <eos> transmission <eos> <eos> <eos> <eos> <eos> <eos> <eos> matching <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 46 | Train Loss: 0.0551 | Val Loss: 6.3874\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: tenggiling mungkin merupakan inang akhir untuk beta-cov kerabat sars-cov-2, mirip dengan musang dalam kasus sars-cov.\n",
            "Decoder Input: <sos> they might be a dead-end host for sars-cov-2-related beta-covs, similar to civets in the case of sars-cov.\n",
            "Expected Output: they might be a dead-end host for sars-cov-2-related beta-covs, similar to civets in the case of sars-cov. <eos>\n",
            "Model Prediction: they might be a dead-end host for sars-cov-2-related beta-covs, similar to civets in the case of sars-cov. <eos> <eos> <eos> <eos> for <eos> for civets <eos> <eos> <eos> for <eos> <eos> <eos> <eos> <eos> civets <eos> <eos> <eos> <eos> for <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> civets for <eos> <eos> for <eos> <eos> for\n",
            "\n",
            "Epoch 47 | Train Loss: 0.0532 | Val Loss: 6.4148\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: alasan pasti untuk perbedaan berdasarkan jenis kelamin ini tidak diketahui, tetapi faktor genetik dan perilaku mungkin menjadi alasan.\n",
            "Decoder Input: <sos> the exact reasons for this sex-difference is not known, but genetic and behavioural factors could be a reason.\n",
            "Expected Output: the exact reasons for this sex-difference is not known, but genetic and behavioural factors could be a reason. <eos>\n",
            "Model Prediction: the exact reasons for this sex-difference is not known, but genetic and behavioural factors could be a reason. <eos> <eos> <eos> <eos> <eos> <eos> but <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> but <eos> <eos> <eos> <eos> but <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> but\n",
            "\n",
            "Epoch 48 | Train Loss: 0.0519 | Val Loss: 6.4033\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: mers-cov muncul pada manusia dari kelelawar melalui inang perantara unta.\n",
            "Decoder Input: <sos> mers-cov emerged in humans from bats through the intermediate host of camels.\n",
            "Expected Output: mers-cov emerged in humans from bats through the intermediate host of camels. <eos>\n",
            "Model Prediction: mers-cov emerged in humans from bats through the intermediate host of camels. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 49 | Train Loss: 0.0504 | Val Loss: 6.4083\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: ketiga, karena terbatasnya ketersediaan pengujian di banyak yurisdiksi selama periode ini, analisis ini mungkin bias ke arah kasus yang lebih berat, dan temuan mungkin berubah setelah pengujian lebih tersebar luas.\n",
            "Decoder Input: <sos> third, because of the limited availability of testing in many jurisdictions during this period, this analysis is likely biased toward more severe cases, and findings might change as testing becomes more widespread.\n",
            "Expected Output: third, because of the limited availability of testing in many jurisdictions during this period, this analysis is likely biased toward more severe cases, and findings might change as testing becomes more widespread. <eos>\n",
            "Model Prediction: third, because of the limited availability of testing in many jurisdictions during this period, this analysis is likely biased toward more severe cases, and findings might change as testing becomes more widespread. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 50 | Train Loss: 0.0490 | Val Loss: 6.4287\n",
            "Checkpoint saved at epoch 50\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: meski masih banyak pertanyaan yang belum terjawab, kami berharap tinjauan ini membantu pemahaman dan pemberantasan penyakit yang mengancam ini.\n",
            "Decoder Input: <sos> although many questions still require answers, we hope that this review helps in the understanding and eradication of the threatening disease.\n",
            "Expected Output: although many questions still require answers, we hope that this review helps in the understanding and eradication of the threatening disease. <eos>\n",
            "Model Prediction: although many questions still require answers, we hope that this review helps in the understanding and eradication of the threatening disease. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 51 | Train Loss: 0.0472 | Val Loss: 6.4412\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: ace2 manusia ditemukan merupakan reseptor untuk sars-cov-2 seperti juga sars-cov.\n",
            "Decoder Input: <sos> human ace2 was found to be a receptor for sars-cov-2 as well as sars-cov.\n",
            "Expected Output: human ace2 was found to be a receptor for sars-cov-2 as well as sars-cov. <eos>\n",
            "Model Prediction: human ace2 was found to be a receptor for sars-cov-2 as well as sars-cov. <eos> <eos> <eos> <eos> <eos> <eos> for for for for <eos> <eos> for <eos> <eos> <eos> <eos> <eos> <eos> for for for for <eos> <eos> for for for for for <eos> <eos>\n",
            "\n",
            "Epoch 52 | Train Loss: 0.0462 | Val Loss: 6.4438\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: pada hari yang sama, presiden trump menandatangani coronavirus preparedness and response supplementsal appropriations act, yang menyediakan dana darurat sebesar $8,3 miliar bagi agen-agen federal untuk merespons wabah.\n",
            "Decoder Input: <sos> on the same day president trump signed the coronavirus preparedness and response supplemental appropriations act, which provided $8.3 billion in emergency funding for federal agencies to respond to the outbreak.\n",
            "Expected Output: on the same day president trump signed the coronavirus preparedness and response supplemental appropriations act, which provided $8.3 billion in emergency funding for federal agencies to respond to the outbreak. <eos>\n",
            "Model Prediction: on the same day president trump signed the coronavirus preparedness and response supplemental appropriations act, which provided $8.3 billion in emergency funding for federal agencies to respond to the outbreak. <eos> against <eos> <eos> against for against against against <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 53 | Train Loss: 0.0454 | Val Loss: 6.4563\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: per 28 maret, terdapat 32.308 kasus terkonfirmasi di kota new york dan 672 orang meninggal akibat virus ini. pada 26 maret, amerika serikat dilaporkan memiliki kasus infeksi koronavirus terkonfirmasi lebih banyak daripada negara mana pun di dunia, termasuk tiongkok dan italia. hingga 8 april, ada 400.335 kasus terkonfirmasi di amerika serikat dan 12.841 orang meninggal dunia.\n",
            "Decoder Input: <sos> as of 28 march, there were 32,308 confirmed cases in new york city, and 672 people had died from the virus.on 26 march, the united states was reported to have more confirmed coronavirus infection cases than any other country in the world, including china and italy.as of 8 april, 400,335 cases have been confirmed in the united states, and 12,841 people have died.\n",
            "Expected Output: as of 28 march, there were 32,308 confirmed cases in new york city, and 672 people had died from the virus.on 26 march, the united states was reported to have more confirmed coronavirus infection cases than any other country in the world, including china and italy.as of 8 april, 400,335 cases have been confirmed in the united states, and 12,841 people have died. <eos>\n",
            "Model Prediction: as of 28 march, there were 32,308 confirmed cases in new york city, and 672 people had died from the virus.on 26 march, the united states was reported to have more confirmed coronavirus infection cases than any other country in the world, including china and italy.as of 8 april, 400,335 cases have been confirmed in the united states, and 12,841 people have died. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 54 | Train Loss: 0.0437 | Val Loss: 6.4555\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: data yang dilaporkan kepada cdc adalah data awal dan dapat diperbarui oleh departemen kesehatan seiring waktu; unsur data penting mungkin tidak ada pada waktu laporan awal; karena itu, analisis ini bersifat deskriptif dan tidak ada pembandingan statistik dapat dilakukan.\n",
            "Decoder Input: <sos> data reported to cdc are preliminary and can be updated by health departments over time; critical data elements might be missing at the time of initial report; thus, this analysis is descriptive, and no statistical comparisons could be made.\n",
            "Expected Output: data reported to cdc are preliminary and can be updated by health departments over time; critical data elements might be missing at the time of initial report; thus, this analysis is descriptive, and no statistical comparisons could be made. <eos>\n",
            "Model Prediction: data reported to cdc are preliminary and can be updated by health departments over time; critical data elements might be missing at the time of initial report; thus, this analysis is descriptive, and no statistical comparisons could be made. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 55 | Train Loss: 0.0427 | Val Loss: 6.4530\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: tetap ikuti perkembangan terkini, wabah dan pembatasan perjalanan berubah dengan cepat.\n",
            "Decoder Input: <sos> keep up to date—the outbreak and the travel restrictions are changing rapidly.\n",
            "Expected Output: keep up to date—the outbreak and the travel restrictions are changing rapidly. <eos>\n",
            "Model Prediction: keep up to date—the outbreak and the travel restrictions are changing rapidly. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 56 | Train Loss: 0.0415 | Val Loss: 6.4568\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: grup privasi di mit media lab mengembangkan safepaths, platform untuk menggunakan teknik yang melindungi privasi saat mengumpulkan dan menggunakan lokasi atau data interseksi alur untuk melacak penyebaran covid-19.\n",
            "Decoder Input: <sos> the privacy group at mit media lab has been developing safepaths, a platform for using privacy-preserving techniques when collecting and using location or path intersection data to track the spread of covid-19.\n",
            "Expected Output: the privacy group at mit media lab has been developing safepaths, a platform for using privacy-preserving techniques when collecting and using location or path intersection data to track the spread of covid-19. <eos>\n",
            "Model Prediction: the privacy group at mit media lab has been developing safepaths, a platform for using privacy-preserving techniques when collecting and using location or path intersection data to track the spread of covid-19. <eos> or or or or or or or or or or or or or or or or covid-19 or or or\n",
            "\n",
            "Epoch 57 | Train Loss: 0.0403 | Val Loss: 6.4861\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: saya akan mengirimkan gambar kepada anda\n",
            "Decoder Input: <sos> i'll send you an image\n",
            "Expected Output: i'll send you an image <eos>\n",
            "Model Prediction: i send you an image <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> you <eos> <eos> you <eos> <eos> send <eos> <eos> you\n",
            "\n",
            "Epoch 58 | Train Loss: 0.0394 | Val Loss: 6.4868\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: modifikasi ini berdasarkan penelitian berkelanjutan para peneliti untuk mencari kit deteksi asam nukleat optimal untuk diagnosis cepat, serta sampel dari saluran napas termasuk pengambilan darah, yang meningkatkan ketersediaan berbagai spesimen, dan mendukung penyertaan hasil positif antibodi tertentu ke dalam kriteria terkonfirmasi.\n",
            "Decoder Input: <sos> these modifications based on the researchers continued work that to search for an optimal nucleic acid detection kit for rapid diagnosis, as well as the samples from respiratory tract including blood sampling, which increased the availability of different specimens, and supported bringing the specific antibody positive result into the confirmed criteria.\n",
            "Expected Output: these modifications based on the researchers continued work that to search for an optimal nucleic acid detection kit for rapid diagnosis, as well as the samples from respiratory tract including blood sampling, which increased the availability of different specimens, and supported bringing the specific antibody positive result into the confirmed criteria. <eos>\n",
            "Model Prediction: these modifications based on the researchers continued work that to search for an optimal nucleic acid detection kit for rapid diagnosis, as well as the samples from respiratory tract including blood sampling, which increased the availability of different specimens, and supported bringing the specific antibody positive result into the confirmed criteria. <eos>\n",
            "\n",
            "Epoch 59 | Train Loss: 0.0378 | Val Loss: 6.4915\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: pada 5 maret 2020, universitas washington di st. louis mengumumkan proyeknya untuk mengembangkan vaksin.\n",
            "Decoder Input: <sos> on 5 march 2020, washington university in st. louis announced its projects to develop a vaccine.\n",
            "Expected Output: on 5 march 2020, washington university in st. louis announced its projects to develop a vaccine. <eos>\n",
            "Model Prediction: on 5 march 2020, washington university in st. louis announced its projects to develop a vaccine. <eos> its its <eos> <eos> its <eos> its its its its its its its its its its <eos> its its <eos> its its its its its its its its its its its its its <eos> <eos> its its its its its its its <eos> its its its against its <eos> its <eos> its its its its its <eos> its its its\n",
            "\n",
            "Epoch 60 | Train Loss: 0.0364 | Val Loss: 6.5045\n",
            "Checkpoint saved at epoch 60\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: dengan menargetkan angka reproduksi (r) (angka rata-rata kasus sekunder yang dihasilkan setiap kasus) dan bertujuan menurunkan r hingga di bawah 1, kebijakan ini berupaya untuk menurunkan jumlah kasus hingga tingkat rendah atau (sebagaimana terlihat pada wabah sebelumnya yakni sindrom pernapasan akut bawah dan ebola) untuk menghilangkan transmisi manusia-ke-manusia.\n",
            "Decoder Input: <sos> by targeting the reproduction number (r) (the average number of secondary cases each case generates) and aiming to reduce the r to below 1, the policy seeks to reduce case numbers to low levels or (as seen in previous outbreaks with severe acute respiratory syndrome and ebola) to eliminate human-to-human transmission.\n",
            "Expected Output: by targeting the reproduction number (r) (the average number of secondary cases each case generates) and aiming to reduce the r to below 1, the policy seeks to reduce case numbers to low levels or (as seen in previous outbreaks with severe acute respiratory syndrome and ebola) to eliminate human-to-human transmission. <eos>\n",
            "Model Prediction: by targeting the reproduction number (r) (the average number of secondary cases each case generates) and aiming to reduce the r to below 1, the policy seeks to reduce case numbers to low levels or (as seen in previous outbreaks with severe acute respiratory syndrome and ebola) to eliminate human-to-human transmission. <eos>\n",
            "\n",
            "Epoch 61 | Train Loss: 0.0350 | Val Loss: 6.4837\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: di antara rangka-rangka baca ini terseling rangka baca untuk protein aksesori.\n",
            "Decoder Input: <sos> interspersed between these reading frames are the reading frames for the accessory proteins.\n",
            "Expected Output: interspersed between these reading frames are the reading frames for the accessory proteins. <eos>\n",
            "Model Prediction: interspersed between these reading frames are the reading frames for the accessory proteins. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> for <eos> <eos> <eos> <eos> for for <eos> for for <eos> <eos> <eos> <eos> for <eos> for <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 62 | Train Loss: 0.0301 | Val Loss: 6.5033\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: untuk diagnosis “kasus terduga” dan “kasus terkonfirmasi”, kami menyarankan untuk mengikuti dan mematuhi panduan terbaru di negara masing-masing.\n",
            "Decoder Input: <sos> for the diagnosis of “suspected case” and “confirmed case”, we suggest to trace and obey the newest guidelines of their home countries.\n",
            "Expected Output: for the diagnosis of “suspected case” and “confirmed case”, we suggest to trace and obey the newest guidelines of their home countries. <eos>\n",
            "Model Prediction: for the diagnosis of “suspected case” and “confirmed case”, we suggest to trace and obey the newest guidelines of their home countries. <eos> for for <eos> <eos> for <eos> for <eos> <eos> <eos> for for <eos> for for for <eos> for for <eos> for for for for for <eos> for <eos> for for <eos> for for for <eos>\n",
            "\n",
            "Epoch 63 | Train Loss: 0.0292 | Val Loss: 6.5112\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: pada 13 maret, ia mengumumkan keadaan darurat nasional sehingga dana federal tersedia untuk merespons krisis.\n",
            "Decoder Input: <sos> on 13 march, he declared a national emergency, which made federal funds available to respond to the crisis.\n",
            "Expected Output: on 13 march, he declared a national emergency, which made federal funds available to respond to the crisis. <eos>\n",
            "Model Prediction: on 13 march, he declared a national emergency, which made federal funds available to respond to the crisis. <eos> for for for for on for on for on for for on for for for for for on on for for for for on on for for for on on on on for for for for for on for for for for for\n",
            "\n",
            "Epoch 64 | Train Loss: 0.0287 | Val Loss: 6.5229\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: opasitas ground-glass multilobar bilateral dengan distribusi perifer, asimetris, dan posterior banyak ditemui di awal infeksi.\n",
            "Decoder Input: <sos> bilateral multilobar ground-glass opacities with a peripheral, asymmetric and posterior distribution are common in early infection.\n",
            "Expected Output: bilateral multilobar ground-glass opacities with a peripheral, asymmetric and posterior distribution are common in early infection. <eos>\n",
            "Model Prediction: bilateral multilobar ground-glass opacities with a peripheral, asymmetric and posterior distribution are common in early infection. <eos> <eos> <eos> transmission <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> and <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> and <eos> <eos> <eos> <eos> <eos> <eos> <eos> and <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 65 | Train Loss: 0.0280 | Val Loss: 6.5267\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: jaringan neural konvolusi berbasis kecerdasan buatan telah dikembangkan untuk mendeteksi fitur pencitraan virus dengan radiografi dan ct.\n",
            "Decoder Input: <sos> artificial intelligence-based convolutional neural networks have been developed to detect imaging features of the virus with both radiographs and ct.\n",
            "Expected Output: artificial intelligence-based convolutional neural networks have been developed to detect imaging features of the virus with both radiographs and ct. <eos>\n",
            "Model Prediction: artificial intelligence-based convolutional neural networks have been developed to detect imaging features of the virus with both radiographs and ct. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 66 | Train Loss: 0.0274 | Val Loss: 6.5392\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: dari 79 kandidat vaksin yang sedang aktif dikembangkan (dikonfirmasi pada awal april 2020), 74 di antaranya belum berada dalam evaluasi manusia (masih dalam penelitian \"praklinis\").\n",
            "Decoder Input: <sos> of 79 vaccine candidates in active development (confirmed as of early april 2020), 74 were not yet in human evaluation (still in \"preclinical\" research).\n",
            "Expected Output: of 79 vaccine candidates in active development (confirmed as of early april 2020), 74 were not yet in human evaluation (still in \"preclinical\" research). <eos>\n",
            "Model Prediction: of 79 vaccine candidates in active development (confirmed as of early april 2020), 74 were not yet in human evaluation (still in \"preclinical\" research). <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 67 | Train Loss: 0.0269 | Val Loss: 6.5363\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: pernyataan itu kemudian dikecam oleh konsulat tiongkok di kolkata, dengan menyebutnya \"keliru\".di tiongkok, xenofobia dan rasisme terhadap penduduk non-tionghoa berkobar karena pandemi, dengan orang asing digambarkan sebagai \"sampah asing\" dan ditargetkan untuk \"pembuangan\".\n",
            "Decoder Input: <sos> the remarks were later condemned by the chinese consulate in kolkata, calling it \"erroneous\".in china, xenophobia and racism agains non-chinese residents has been inflamed by the pandemic, with foreigners described as \"foreign garbage\" and targeted for \"disposal\".\n",
            "Expected Output: the remarks were later condemned by the chinese consulate in kolkata, calling it \"erroneous\".in china, xenophobia and racism agains non-chinese residents has been inflamed by the pandemic, with foreigners described as \"foreign garbage\" and targeted for \"disposal\". <eos>\n",
            "Model Prediction: the remarks were later condemned by the chinese consulate in kolkata, calling it \"erroneous\".in china, xenophobia and racism agains non-chinese residents has been inflamed by the pandemic, with foreigners described as \"foreign garbage\" and targeted for \"disposal\". <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 68 | Train Loss: 0.0264 | Val Loss: 6.5424\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: meski demikian, efikasi dan keamanan tcm masih menunggu uji coba yang terkontrol lebih baik pada skala lebih besar dan di lebih banyak pusat penelitian.\n",
            "Decoder Input: <sos> nevertheless, the efficacy and safety of tcm still await more well-controlled trials at larger scales and in more centers.\n",
            "Expected Output: nevertheless, the efficacy and safety of tcm still await more well-controlled trials at larger scales and in more centers. <eos>\n",
            "Model Prediction: nevertheless, the efficacy and safety of tcm still await more well-controlled trials at larger scales and in more centers. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 69 | Train Loss: 0.0260 | Val Loss: 6.5418\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: sars-cov-2 juga dapat membentuk protein pendek baru yang disandikan dengan orf3b dan protein yang disekresikan dengan sandi orf8.\n",
            "Decoder Input: <sos> sars-cov-2 can also form a novel short protein encoded by orf3b and a secreted protein encoded by orf8.\n",
            "Expected Output: sars-cov-2 can also form a novel short protein encoded by orf3b and a secreted protein encoded by orf8. <eos>\n",
            "Model Prediction: sars-cov-2 can also form a novel short protein encoded by orf3b and a secreted protein encoded by orf8. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> protein <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> protein <eos> <eos> <eos> <eos> <eos> protein <eos> <eos> <eos> <eos> protein <eos> <eos> <eos> protein protein <eos> <eos>\n",
            "\n",
            "Epoch 70 | Train Loss: 0.0254 | Val Loss: 6.5443\n",
            "Checkpoint saved at epoch 70\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: banyak negara telah menghentikan atau sangat membatasi penerbangan, kapal, dan perlintasan di perbatasan, terutama ke dan dari daerah yang terdampak.\n",
            "Decoder Input: <sos> many countries have shut down or severely limited flights, ships, and border crossings, especially to and from affected areas.\n",
            "Expected Output: many countries have shut down or severely limited flights, ships, and border crossings, especially to and from affected areas. <eos>\n",
            "Model Prediction: many countries have shut down or severely limited flights, ships, and border crossings, especially to and from affected areas. <eos> especially especially especially especially especially especially especially especially especially especially especially especially especially especially especially especially especially especially especially especially especially especially especially especially especially especially especially especially especially especially especially\n",
            "\n",
            "Epoch 71 | Train Loss: 0.0248 | Val Loss: 6.5665\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: pada 19 maret, uji lantatur ditawarkan di beberapa kota besar.\n",
            "Decoder Input: <sos> as of 19 march drive in tests were offered in several large cities.\n",
            "Expected Output: as of 19 march drive in tests were offered in several large cities. <eos>\n",
            "Model Prediction: as of 19 march drive in tests were offered in several large cities. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> as <eos> as <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 72 | Train Loss: 0.0245 | Val Loss: 6.5612\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: karena kurangnya pengalaman dengan cov baru, dokter terutama menawarkan perawatan pendukung kepada pasien covid-19, selagi mencoba berbagai terapi yang pernah digunakan atau diusulkan sebelumnya untuk perawatan cov lain, seperti sars-cov, mers-cov, dan penyakit viral lainnya (tabel 2).2).\n",
            "Decoder Input: <sos> due to the lack of experience with the novel cov, physicians can mainly provide supportive care to covid-19 patients, while attempting a variety of therapies that have been used or proposed before for the treatment of other covs such as sars-cov and mers-cov and other viral diseases (table ​(table2).2).\n",
            "Expected Output: due to the lack of experience with the novel cov, physicians can mainly provide supportive care to covid-19 patients, while attempting a variety of therapies that have been used or proposed before for the treatment of other covs such as sars-cov and mers-cov and other viral diseases (table ​(table2).2). <eos>\n",
            "Model Prediction: due to the lack of experience with the novel cov, physicians can mainly provide supportive care to covid-19 patients, while attempting a variety of therapies that have been used or proposed before for the treatment of other covs such as sars-cov and mers-cov and other viral diseases (table ​(table2).2). <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 73 | Train Loss: 0.0242 | Val Loss: 6.5653\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: infiltrat limfositik juga pernah dilaporkan pada otopsi.\n",
            "Decoder Input: <sos> lymphocytic infiltrates have also been reported at autopsy.\n",
            "Expected Output: lymphocytic infiltrates have also been reported at autopsy. <eos>\n",
            "Model Prediction: lymphocytic infiltrates have also been reported at autopsy. <eos> <eos> <eos> at <eos> at <eos> at <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 74 | Train Loss: 0.0239 | Val Loss: 6.5757\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: sebagian besar komponen efektif masih belum diketahui atau belum jelas karena sulit untuk mengekstrak atau memverifikasi komponen tersebut atau kombinasi optimalnya.\n",
            "Decoder Input: <sos> most of the effective components remain unknown or are vague as it is difficult to extract and verify such components or their optimal combinations.\n",
            "Expected Output: most of the effective components remain unknown or are vague as it is difficult to extract and verify such components or their optimal combinations. <eos>\n",
            "Model Prediction: most of the effective components remain unknown or are vague as it is difficult to extract and verify such components or their optimal combinations. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 75 | Train Loss: 0.0237 | Val Loss: 6.5934\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: obat antivirus dapat dicoba pada orang dengan penyakit parah.\n",
            "Decoder Input: <sos> antiviral medication may be tried in people with severe disease.\n",
            "Expected Output: antiviral medication may be tried in people with severe disease. <eos>\n",
            "Model Prediction: antiviral medication may be tried in people with severe disease. <eos> <eos> <eos> but <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> but <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 76 | Train Loss: 0.0226 | Val Loss: 6.5843\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: setelah bepergian, pantau kesehatan anda dan pertimbangkan untuk melakukan isolasi mandiri selama dua minggu untuk mencegah menularkan penyakit kepada orang lain.\n",
            "Decoder Input: <sos> after travel, monitor your health and consider self-isolation for two weeks to avoid transmitting the disease to others.\n",
            "Expected Output: after travel, monitor your health and consider self-isolation for two weeks to avoid transmitting the disease to others. <eos>\n",
            "Model Prediction: after travel, monitor your health and consider self-isolation for two weeks to avoid transmitting the disease to others. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> for <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> for <eos> <eos>\n",
            "\n",
            "Epoch 77 | Train Loss: 0.0223 | Val Loss: 6.5867\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: kode ini akan dikelompokkan secara ontologis menjadi “pasti”, “besar kemungkinan”, “kecil kemungkinan”, dan “bukan kasus” menggunakan pendekatan standar untuk mengelompokkan kode (tabel 5), yang telah digunakan sebelumnya di bidang penyakit.\n",
            "Decoder Input: <sos> these codes will be grouped ontologically into “definite”, “probable”, “possible”, and “not a case” using our standard approach to grouping codes (table 5), which has been used previously across disease areas.\n",
            "Expected Output: these codes will be grouped ontologically into “definite”, “probable”, “possible”, and “not a case” using our standard approach to grouping codes (table 5), which has been used previously across disease areas. <eos>\n",
            "Model Prediction: these codes will be grouped ontologically into “definite”, “probable”, “possible”, and “not a case” using our standard approach to grouping codes (table 5), which has been used previously across disease areas. <eos> areas. areas. areas. areas. <eos> <eos> treatment. previously codes areas. 5), areas. areas. areas. areas. <eos> areas. patients. areas. areas. areas. <eos> <eos>\n",
            "\n",
            "Epoch 78 | Train Loss: 0.0220 | Val Loss: 6.6022\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: b'surveilans covid-19 melibatkan pemantauan penyebaran penyakit koronavirus guna menetapkan pola perkembangan penyakit.\n",
            "Decoder Input: <sos> b'covid-19 surveillance involves monitoring the spread of the coronavirus disease in order to establish the patterns of disease progression.\n",
            "Expected Output: b'covid-19 surveillance involves monitoring the spread of the coronavirus disease in order to establish the patterns of disease progression. <eos>\n",
            "Model Prediction: b'covid-19 surveillance involves monitoring the spread of the coronavirus disease in order to establish the patterns of disease progression. <eos> covid-19 covid-19 covid-19 covid-19 <eos> covid-19 <eos> covid-19 <eos> <eos> <eos> covid-19 <eos> <eos> <eos> covid-19 covid-19 covid-19 <eos> <eos> covid-19 covid-19 covid-19 covid-19 covid-19 <eos> covid-19 covid-19 covid-19 covid-19 covid-19 covid-19 covid-19 <eos> covid-19 covid-19 covid-19 <eos> covid-19 covid-19 covid-19 covid-19 covid-19 <eos> covid-19 covid-19 covid-19 covid-19 covid-19 covid-19 covid-19 covid-19 covid-19 covid-19 <eos>\n",
            "\n",
            "Epoch 79 | Train Loss: 0.0220 | Val Loss: 6.5870\n",
            "\n",
            "Sample Batch (Text):\n",
            "Source: lima beta-cov lainnya meliputi hcov-oc43, hcov-hku1, virus korona sindrom pernapasan akut berat (sars-cov), virus korona sindrom pernapasan timur tengah (mers-cov), dan sars-cov-2.\n",
            "Decoder Input: <sos> the other five beta-covs include hcov-oc43, hcov-hku1, severe acute respiratory syndrome coronavirus (sars-cov), middle east respiratory syndrome coronavirus (mers-cov) and sars-cov-2.\n",
            "Expected Output: the other five beta-covs include hcov-oc43, hcov-hku1, severe acute respiratory syndrome coronavirus (sars-cov), middle east respiratory syndrome coronavirus (mers-cov) and sars-cov-2. <eos>\n",
            "Model Prediction: the other five beta-covs include hcov-oc43, hcov-hku1, severe acute respiratory syndrome coronavirus (sars-cov), middle east respiratory syndrome coronavirus (mers-cov) and sars-cov-2. <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos>\n",
            "\n",
            "Epoch 80 | Train Loss: 0.0220 | Val Loss: 6.5856\n",
            "Checkpoint saved at epoch 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference Mode**"
      ],
      "metadata": {
        "id": "O-yTG9yiiy5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import json\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load vocabularies\n",
        "with open('/content/src_vocab.json', 'r') as f:\n",
        "    src_vocab = json.load(f)  # Indonesian vocabulary\n",
        "with open('/content/tgt_vocab.json', 'r') as f:\n",
        "    tgt_vocab = json.load(f)  # English vocabulary\n",
        "\n",
        "# Create reverse vocabulary (ID → word) for English\n",
        "id_to_word = {v: k for k, v in tgt_vocab.items()}\n",
        "\n",
        "def translate_id_to_en(sentence_id, model, src_vocab, tgt_vocab, id_to_word, device, max_length=50):\n",
        "    # Tokenize Indonesian input\n",
        "    tokens = sentence_id.lower().split()\n",
        "    src_ids = [src_vocab.get(token, src_vocab['<unk>']) for token in tokens]\n",
        "    src = torch.tensor([src_ids], dtype=torch.long, device=device)  # [1, src_len]\n",
        "\n",
        "    # Create target input (start with <sos>)\n",
        "    tgt_input = torch.tensor([[tgt_vocab['<sos>']]], dtype=torch.long, device=device)\n",
        "\n",
        "    # Generate translation autoregressively\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_length):\n",
        "            # Create masks\n",
        "            src_mask = (src != src_vocab['<pad>']).unsqueeze(1).unsqueeze(2).to(device)\n",
        "            tgt_mask = torch.tril(torch.ones((tgt_input.size(1), tgt_input.size(1)), device=device)).bool()\n",
        "            tgt_mask = tgt_mask.unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "            # Get model output\n",
        "            output = model(src, tgt_input, src_mask=src_mask, tgt_mask=tgt_mask)\n",
        "\n",
        "            # Get the most likely next token\n",
        "            next_token = output.argmax(dim=-1)[:, -1].unsqueeze(1)\n",
        "\n",
        "            # Append to the target sequence\n",
        "            tgt_input = torch.cat([tgt_input, next_token], dim=-1)\n",
        "\n",
        "            # Stop if we predict <eos>\n",
        "            if next_token.item() == tgt_vocab['<eos>']:\n",
        "                break\n",
        "\n",
        "    # Convert IDs to English text\n",
        "    translation = []\n",
        "    for id in tgt_input[0].cpu().numpy():\n",
        "        if id == tgt_vocab['<eos>']:\n",
        "            break\n",
        "        if id not in [tgt_vocab['<pad>'], tgt_vocab['<sos>']]:\n",
        "            translation.append(id_to_word[id])\n",
        "\n",
        "    return ' '.join(translation)\n",
        "\n",
        "# Initialize model\n",
        "model = Transformer(\n",
        "    embed_dim=512,\n",
        "    num_heads=8,\n",
        "    ff_dim=2048,\n",
        "    num_encoder_layers=6,\n",
        "    num_decoder_layers=6,\n",
        "    input_vocab_size=len(src_vocab),\n",
        "    target_vocab_size=len(tgt_vocab),\n",
        "    max_seq_len=500\n",
        ").to(device)\n",
        "\n",
        "# Load trained weights\n",
        "model.load_state_dict(torch.load('/content/best_transformer_model.pt', map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# Example translation\n",
        "input_id = \"berdasarkan hal ini, gilead menyediakan senyawa ini bagi tiongkok untuk melakukan serangkaian uji coba pada orang terinfeksi sars-cov-2, dan hasilnya sangat dinantikan.\"\n",
        "output_en = translate_id_to_en(input_id, model, src_vocab, tgt_vocab, id_to_word, device)\n",
        "print(f\"Indonesian: {input_id}\")\n",
        "print(f\"English: {output_en}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kxrcq8Xxi1rO",
        "outputId": "b92bc5c4-dfee-4ba5-bdb2-a033cb76bc54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indonesian: berdasarkan hal ini, gilead menyediakan senyawa ini bagi tiongkok untuk melakukan serangkaian uji coba pada orang terinfeksi sars-cov-2, dan hasilnya sangat dinantikan.\n",
            "English: for this study in china to the chinese government has been used for this coming in china and the treatment of the treatment of the treatment of the results are being tested positive for people to determine the results and the results to determine the results and the results has\n"
          ]
        }
      ]
    }
  ]
}